{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c36f2ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5fc66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to create models for different stocks and save them to .keras files\n",
    "\n",
    "scalers={}\n",
    "training_data_lens={}\n",
    "\n",
    "def create_models(stock_name):\n",
    "    df= pd.read_csv(f\"stock_data/{stock_name}_last_5_years.csv\")\n",
    "    df['Date']=pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "    target_col='Close'\n",
    "\n",
    "    dataset=df[target_col].values.reshape(-1,1)\n",
    "    training_data_len=int(np.ceil(len(dataset) * 0.95))\n",
    "    training_data_lens[stock_name]=training_data_len\n",
    "    # print(f\"Training data length = {training_data_len}\")\n",
    "\n",
    "\n",
    "    #Preprocessing data (scaling)\n",
    "    scaler=StandardScaler()\n",
    "    scaled_data=scaler.fit_transform(dataset)\n",
    "    scalers[stock_name]=scaler\n",
    "\n",
    "    #Create training data\n",
    "    train_data=scaled_data[:training_data_len]\n",
    "\n",
    "    X_train=[]\n",
    "    y_train=[]\n",
    "\n",
    "    #Creating 60 days sliding window for LSTM\n",
    "    for i in range(60, len(train_data)):\n",
    "        X_train.append(train_data[i-60:i, 0])   #60 previous days\n",
    "        y_train.append(train_data[i, 0])        #61st day\n",
    "    \n",
    "    #Reshaping data for LSTM input(samples, time_steps, features)\n",
    "    X_train, y_train=np.array(X_train), np.array(y_train)\n",
    "    X_train=np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "    #Build LSTM model\n",
    "    model=keras.Sequential()\n",
    "\n",
    "    #First layer\n",
    "    model.add(keras.layers.LSTM(units=64,return_sequences=True,input_shape=(X_train.shape[1],1)))\n",
    "\n",
    "    #Second layer\n",
    "    model.add(keras.layers.LSTM(units=64,return_sequences=False))\n",
    "\n",
    "    #Third layer\n",
    "    model.add(keras.layers.Dense(units=25))\n",
    "\n",
    "    #Fourth layer\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "    #Final output layer\n",
    "    model.add(keras.layers.Dense(units=1))\n",
    "\n",
    "    # model.summary()\n",
    "\n",
    "    model.compile(optimizer='adam',loss='mae', metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "    model.fit(X_train,y_train, epochs=20, batch_size=32)\n",
    "\n",
    "    model.save(f\"models/{stock_name}_model.keras\")\n",
    "\n",
    "    joblib.dump(scaler, f\"models/scalers/{stock_name}_scaler.joblib\")\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e413adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build models and predict for multiple stocks and visualize the test results\n",
    "\n",
    "def train_models_for_stocks(stock_name):\n",
    "    print(f\"Creating model for {stock_name}...\")\n",
    "    model=create_models(stock_name)\n",
    "    print(f\"Model for {stock_name} created and saved.\\n\")\n",
    "\n",
    "    #Testing the model\n",
    "    df= pd.read_csv(f\"stock_data/{stock_name}_last_5_years.csv\")\n",
    "    df['Date']=pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "    target_col='Close'\n",
    "    dataset=df[target_col].values.reshape(-1,1)\n",
    "    training_data_len=training_data_lens[stock_name]\n",
    "\n",
    "    #get the scaler object\n",
    "    scaler=scalers[stock_name]\n",
    "\n",
    "    test_data=dataset[training_data_len - 60:]\n",
    "    scaled_test_data=scaler.transform(test_data)\n",
    "\n",
    "    #Prepare the test data\n",
    "    X_test=[]\n",
    "    y_test=dataset[training_data_len:]\n",
    "\n",
    "    for i in range(60, len(scaled_test_data)):\n",
    "        X_test.append(scaled_test_data[i-60:i, 0])\n",
    "\n",
    "\n",
    "    X_test=np.array(X_test)\n",
    "    X_test=np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    #Make a predictions\n",
    "    predictions=model.predict(X_test)\n",
    "    predictions=scaler.inverse_transform(predictions)\n",
    "\n",
    "    #Plotting the data and the predictions (saved in outputs folder)\n",
    "    train=df[:training_data_len]\n",
    "    valid=df[training_data_len:]\n",
    "\n",
    "    valid['Predictions']=predictions\n",
    "\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.title(f\"{stock_name} Stock Price Prediction\")\n",
    "    plt.xlabel('Date', fontsize=18)\n",
    "    plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "    plt.plot(train['Date'], train['Close'], label='Train Close Price')\n",
    "    plt.plot(valid['Date'], valid['Close'], label='Actual Close Price')\n",
    "    plt.plot(valid['Date'], valid['Predictions'], label='Predicted Close Price')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"outputs/{stock_name}/stock_price_prediction.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Prediction plot for {stock_name} saved in outputs folder.\\n\")\n",
    "\n",
    "\n",
    "    #Evaluate the model\n",
    "    rmse=np.sqrt(np.mean(((predictions - y_test)**2))) \n",
    "    print(f\"Root Mean Squared Error for {stock_name}: {rmse}\")\n",
    "\n",
    "    print(\"\\n---------------------------------\\n\")\n",
    "    return rmse\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8f9bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model for AAPL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anshul Guleria\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.3009 - root_mean_squared_error: 0.4168\n",
      "Epoch 2/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.1987 - root_mean_squared_error: 0.2635\n",
      "Epoch 3/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.1961 - root_mean_squared_error: 0.2597\n",
      "Epoch 4/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.1825 - root_mean_squared_error: 0.2452\n",
      "Epoch 5/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.1766 - root_mean_squared_error: 0.2390\n",
      "Epoch 6/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.1807 - root_mean_squared_error: 0.2451\n",
      "Epoch 7/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.1667 - root_mean_squared_error: 0.2243\n",
      "Epoch 8/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.1749 - root_mean_squared_error: 0.2402\n",
      "Epoch 9/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.1647 - root_mean_squared_error: 0.2279\n",
      "Epoch 10/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.1529 - root_mean_squared_error: 0.2119\n",
      "Epoch 11/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.1564 - root_mean_squared_error: 0.2155\n",
      "Epoch 12/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.1626 - root_mean_squared_error: 0.2225\n",
      "Epoch 13/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.1623 - root_mean_squared_error: 0.2223\n",
      "Epoch 14/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.1606 - root_mean_squared_error: 0.2175\n",
      "Epoch 15/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.1558 - root_mean_squared_error: 0.2145\n",
      "Epoch 16/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.1513 - root_mean_squared_error: 0.2044\n",
      "Epoch 17/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.1550 - root_mean_squared_error: 0.2086\n",
      "Epoch 18/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.1530 - root_mean_squared_error: 0.2126\n",
      "Epoch 19/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.1516 - root_mean_squared_error: 0.2089\n",
      "Epoch 20/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.1477 - root_mean_squared_error: 0.2037\n",
      "Model for AAPL created and saved.\n",
      "\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
      "Prediction plot for AAPL saved in outputs folder.\n",
      "\n",
      "Root Mean Squared Error for AAPL: 6.019528987716889\n",
      "\n",
      "---------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anshul Guleria\\AppData\\Local\\Temp\\ipykernel_18884\\4046769420.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid['Predictions']=predictions\n"
     ]
    }
   ],
   "source": [
    "stocks_list=[\"AAPL\",\"MSFT\",\"GOOGL\",\"AMZN\",\"TSLA\"]\n",
    "# stocks_list=[\"AAPL\"]\n",
    "RMSE_results={}\n",
    "for stock in stocks_list:\n",
    "    RMSE_results[stock]=train_models_for_stocks(stock)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b898925c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Results for all stocks:\n",
      "AAPL: 6.019528987716889\n"
     ]
    }
   ],
   "source": [
    "#Display RMSE results for all stocks\n",
    "print(\"RMSE Results for all stocks:\")\n",
    "for stock, rmse in RMSE_results.items():\n",
    "    print(f\"{stock}: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28622281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be7c5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110101c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855abac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
