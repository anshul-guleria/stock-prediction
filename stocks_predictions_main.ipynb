{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c36f2ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c5fc66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to create models for different stocks and save them to .keras files\n",
    "\n",
    "scalers={}\n",
    "training_data_lens={}\n",
    "\n",
    "def create_models(stock_name):\n",
    "    df= pd.read_csv(f\"stock_data/{stock_name}_last_5_years.csv\")\n",
    "    df['Date']=pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "    target_col='Close'\n",
    "\n",
    "    dataset=df[target_col].values.reshape(-1,1)\n",
    "    training_data_len=int(np.ceil(len(dataset) * 0.95))\n",
    "    training_data_lens[stock_name]=training_data_len\n",
    "    # print(f\"Training data length = {training_data_len}\")\n",
    "\n",
    "\n",
    "    #Preprocessing data (scaling)\n",
    "    scaler=StandardScaler()\n",
    "    scaled_data=scaler.fit_transform(dataset)\n",
    "    scalers[stock_name]=scaler\n",
    "\n",
    "    #Create training data\n",
    "    train_data=scaled_data[:training_data_len]\n",
    "\n",
    "    X_train=[]\n",
    "    y_train=[]\n",
    "\n",
    "    #Creating 60 days sliding window for LSTM\n",
    "    for i in range(60, len(train_data)):\n",
    "        X_train.append(train_data[i-60:i, 0])   #60 previous days\n",
    "        y_train.append(train_data[i, 0])        #61st day\n",
    "    \n",
    "    #Reshaping data for LSTM input(samples, time_steps, features)\n",
    "    X_train, y_train=np.array(X_train), np.array(y_train)\n",
    "    X_train=np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "    #Build LSTM model\n",
    "    model=keras.Sequential()\n",
    "\n",
    "    #First layer\n",
    "    model.add(keras.layers.LSTM(units=64,return_sequences=True,input_shape=(X_train.shape[1],1)))\n",
    "\n",
    "    #Second layer\n",
    "    model.add(keras.layers.LSTM(units=64,return_sequences=False))\n",
    "\n",
    "    #Third layer\n",
    "    model.add(keras.layers.Dense(units=25))\n",
    "\n",
    "    #Fourth layer\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "    #Final output layer\n",
    "    model.add(keras.layers.Dense(units=1))\n",
    "\n",
    "    # model.summary()\n",
    "\n",
    "    model.compile(optimizer='adam',loss='mae', metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "    model.fit(X_train,y_train, epochs=20, batch_size=32)\n",
    "\n",
    "    model.save(f\"models/{stock_name}_model.keras\")\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e413adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build models and predict for multiple stocks and visualize the test results\n",
    "\n",
    "def train_models_for_stocks(stock_name):\n",
    "    print(f\"Creating model for {stock_name}...\")\n",
    "    model=create_models(stock_name)\n",
    "    print(f\"Model for {stock_name} created and saved.\\n\")\n",
    "\n",
    "    #Testing the model\n",
    "    df= pd.read_csv(f\"stock_data/{stock_name}_last_5_years.csv\")\n",
    "    df['Date']=pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "    target_col='Close'\n",
    "    dataset=df[target_col].values.reshape(-1,1)\n",
    "    training_data_len=training_data_lens[stock_name]\n",
    "\n",
    "    #get the scaler object\n",
    "    scaler=scalers[stock_name]\n",
    "\n",
    "    test_data=dataset[training_data_len - 60:]\n",
    "    scaled_test_data=scaler.transform(test_data)\n",
    "\n",
    "    #Prepare the test data\n",
    "    X_test=[]\n",
    "    y_test=dataset[training_data_len:]\n",
    "\n",
    "    for i in range(60, len(scaled_test_data)):\n",
    "        X_test.append(scaled_test_data[i-60:i, 0])\n",
    "\n",
    "\n",
    "    X_test=np.array(X_test)\n",
    "    X_test=np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    #Make a predictions\n",
    "    predictions=model.predict(X_test)\n",
    "    predictions=scaler.inverse_transform(predictions)\n",
    "\n",
    "    #Plotting the data and the predictions (saved in outputs folder)\n",
    "    train=df[:training_data_len]\n",
    "    valid=df[training_data_len:]\n",
    "\n",
    "    valid['Predictions']=predictions\n",
    "\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.title(f\"{stock_name} Stock Price Prediction\")\n",
    "    plt.xlabel('Date', fontsize=18)\n",
    "    plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "    plt.plot(train['Date'], train['Close'], label='Train Close Price')\n",
    "    plt.plot(valid['Date'], valid['Close'], label='Actual Close Price')\n",
    "    plt.plot(valid['Date'], valid['Predictions'], label='Predicted Close Price')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"outputs/{stock_name}_stock_price_prediction.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Prediction plot for {stock_name} saved in outputs folder.\\n\")\n",
    "\n",
    "\n",
    "    #Evaluate the model\n",
    "    rmse=np.sqrt(np.mean(((predictions - y_test)**2))) \n",
    "    print(f\"Root Mean Squared Error for {stock_name}: {rmse}\")\n",
    "\n",
    "    print(\"\\n---------------------------------\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8f9bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28622281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be7c5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110101c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855abac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
